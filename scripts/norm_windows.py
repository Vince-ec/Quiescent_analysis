import numpy as npfrom scipy.interpolate import interp1d, interp2dimport matplotlib.pyplot as pltfrom vtl.Readfile import Readfilefrom astropy.io import fitsimport cPickleimport osfrom spec_id import Stack_spec_normwmean,Analyze_Stack_avgage,Likelihood_contours,Identify_stack,\    Analyze_Stack, Scale_modelfrom glob import globimport seaborn as seasea.set(style='white')sea.set(style='ticks')sea.set_style({"xtick.direction": "in","ytick.direction": "in"})colmap = sea.cubehelix_palette(12, start=2, rot=.2, dark=0, light=1.1, as_cmap=True)def Stack_spec_normwmean_tot(spec,redshifts, wv):    flgrid=np.zeros([len(spec),len(wv)])    errgrid=np.zeros([len(spec),len(wv)])    for i in range(len(spec)):        wave, flux, error = np.array(Readfile(spec[i], 1))        wave /= (1 + redshifts[i])        mask = np.array([wave[0] < U < wave[-1] for U in wv])        newsig = np.sqrt(error ** 2 + (flux * .1) ** 2)        ifl=interp1d(wave,flux)        ier=interp1d(wave,newsig)        reg = np.arange(4000, 4910, 1)        Cr = np.trapz(ifl(reg), reg)        flgrid[i][mask] = ifl(wv[mask]) / Cr        errgrid[i][mask] = ier(wv[mask]) / Cr    ################    flgrid=np.transpose(flgrid)    errgrid=np.transpose(errgrid)    weigrid=errgrid**(-2)    infmask=np.isinf(weigrid)    weigrid[infmask]=0    ################    stack,err=np.zeros([2,len(wv)])    for i in range(len(wv)):        stack[i]=np.sum(flgrid[i]*weigrid[[i]])/np.sum(weigrid[i])        err[i]=1/np.sqrt(np.sum(weigrid[i]))    ################    ###take out nans    IDX=[U for U in range(len(wv)) if stack[U] > 0]    return wv[IDX], stack[IDX], err[IDX]def Stack_spec_normwmean_blue(spec,redshifts, wv):    flgrid=np.zeros([len(spec),len(wv)])    errgrid=np.zeros([len(spec),len(wv)])    for i in range(len(spec)):        wave, flux, error = np.array(Readfile(spec[i], 1))        wave /= (1 + redshifts[i])        mask = np.array([wave[0] < U < wave[-1] for U in wv])        newsig = np.sqrt(error ** 2 + (flux * .1) ** 2)        ifl=interp1d(wave,flux)        ier=interp1d(wave,newsig)        reg = np.arange(4000, 4210, 1)        Cr = np.trapz(ifl(reg), reg)        flgrid[i][mask] = ifl(wv[mask]) / Cr        errgrid[i][mask] = ier(wv[mask]) / Cr    ################    flgrid=np.transpose(flgrid)    errgrid=np.transpose(errgrid)    weigrid=errgrid**(-2)    infmask=np.isinf(weigrid)    weigrid[infmask]=0    ################    stack,err=np.zeros([2,len(wv)])    for i in range(len(wv)):        stack[i]=np.sum(flgrid[i]*weigrid[[i]])/np.sum(weigrid[i])        err[i]=1/np.sqrt(np.sum(weigrid[i]))    ################    ###take out nans    IDX=[U for U in range(len(wv)) if stack[U] > 0]    return wv[IDX], stack[IDX], err[IDX]def Stack_spec_normwmean_red(spec,redshifts, wv):    flgrid=np.zeros([len(spec),len(wv)])    errgrid=np.zeros([len(spec),len(wv)])    for i in range(len(spec)):        wave, flux, error = np.array(Readfile(spec[i], 1))        wave /= (1 + redshifts[i])        mask = np.array([wave[0] < U < wave[-1] for U in wv])        newsig = np.sqrt(error ** 2 + (flux * .1) ** 2)        ifl=interp1d(wave,flux)        ier=interp1d(wave,newsig)        reg = np.arange(4700, 4910, 1)        Cr = np.trapz(ifl(reg), reg)        flgrid[i][mask] = ifl(wv[mask]) / Cr        errgrid[i][mask] = ier(wv[mask]) / Cr    ################    flgrid=np.transpose(flgrid)    errgrid=np.transpose(errgrid)    weigrid=errgrid**(-2)    infmask=np.isinf(weigrid)    weigrid[infmask]=0    ################    stack,err=np.zeros([2,len(wv)])    for i in range(len(wv)):        stack[i]=np.sum(flgrid[i]*weigrid[[i]])/np.sum(weigrid[i])        err[i]=1/np.sqrt(np.sum(weigrid[i]))    ################    ###take out nans    IDX=[U for U in range(len(wv)) if stack[U] > 0]    return wv[IDX], stack[IDX], err[IDX]def Stack_model_normwmean_tot(speclist, modellist, redshifts, redshiftbins, wv_range):    flgrid =[]    errgrid = []    for i in range(len(speclist)):        #######read in spectra        wave,flux,error1=np.array(Readfile(speclist[i],1))        wave=wave/(1+redshifts[i])        error = np.sqrt(error1 ** 2 + (flux * .1) ** 2)        #######read in corresponding model, and interpolate flux        W,F,E=np.array(Readfile(modellist[i],1))        W=W/(1+redshiftbins[i])        iF=interp1d(W,F)(wave)        #######scale the model        C=Scale_model(flux,error,iF)        mflux=C*iF        # Fl = iF        Fl = mflux        Er = error        ########interpolate spectra        flentry=np.zeros(len(wv_range))        errentry=np.zeros(len(wv_range))        mask = np.array([wave[0] < U < wave[-1] for U in wv_range])        ifl=interp1d(wave,Fl)        ier=interp1d(wave,Er)        reg = np.arange(4000, 4910, 1)        Cr = np.trapz(ifl(reg), reg)        flentry[mask] = ifl(wv_range[mask]) / Cr        errentry[mask] = ier(wv_range[mask]) / Cr        flgrid.append(flentry)        errgrid.append(errentry)    wv = np.array(wv_range)    flgrid=np.transpose(flgrid)    errgrid=np.transpose(errgrid)    weigrid=errgrid**(-2)    infmask=np.isinf(weigrid)    weigrid[infmask]=0    ################    stack,err=np.zeros([2,len(wv)])    for i in range(len(wv)):        stack[i]=np.sum(flgrid[i]*weigrid[[i]])/np.sum(weigrid[i])        err[i]=1/np.sqrt(np.sum(weigrid[i]))    ################    return wv, stack, errdef Stack_model_normwmean_blue(speclist, modellist, redshifts, redshiftbins, wv_range):    flgrid =[]    errgrid = []    for i in range(len(speclist)):        #######read in spectra        wave,flux,error1=np.array(Readfile(speclist[i],1))        wave=wave/(1+redshifts[i])        error = np.sqrt(error1 ** 2 + (flux * .1) ** 2)        #######read in corresponding model, and interpolate flux        W,F,E=np.array(Readfile(modellist[i],1))        W=W/(1+redshiftbins[i])        iF=interp1d(W,F)(wave)        #######scale the model        C=Scale_model(flux,error,iF)        mflux=C*iF        # Fl = iF        Fl = mflux        Er = error        ########interpolate spectra        flentry=np.zeros(len(wv_range))        errentry=np.zeros(len(wv_range))        mask = np.array([wave[0] < U < wave[-1] for U in wv_range])        ifl=interp1d(wave,Fl)        ier=interp1d(wave,Er)        reg = np.arange(4000, 4210, 1)        Cr = np.trapz(ifl(reg), reg)        flentry[mask] = ifl(wv_range[mask]) / Cr        errentry[mask] = ier(wv_range[mask]) / Cr        flgrid.append(flentry)        errgrid.append(errentry)    wv = np.array(wv_range)    flgrid=np.transpose(flgrid)    errgrid=np.transpose(errgrid)    weigrid=errgrid**(-2)    infmask=np.isinf(weigrid)    weigrid[infmask]=0    ################    stack,err=np.zeros([2,len(wv)])    for i in range(len(wv)):        stack[i]=np.sum(flgrid[i]*weigrid[[i]])/np.sum(weigrid[i])        err[i]=1/np.sqrt(np.sum(weigrid[i]))    ################    return wv, stack, errdef Stack_model_normwmean_red(speclist, modellist, redshifts, redshiftbins, wv_range):    flgrid =[]    errgrid = []    for i in range(len(speclist)):        #######read in spectra        wave,flux,error1=np.array(Readfile(speclist[i],1))        wave=wave/(1+redshifts[i])        error = np.sqrt(error1 ** 2 + (flux * .1) ** 2)        #######read in corresponding model, and interpolate flux        W,F,E=np.array(Readfile(modellist[i],1))        W=W/(1+redshiftbins[i])        iF=interp1d(W,F)(wave)        #######scale the model        C=Scale_model(flux,error,iF)        mflux=C*iF        # Fl = iF        Fl = mflux        Er = error        ########interpolate spectra        flentry=np.zeros(len(wv_range))        errentry=np.zeros(len(wv_range))        mask = np.array([wave[0] < U < wave[-1] for U in wv_range])        ifl=interp1d(wave,Fl)        ier=interp1d(wave,Er)        reg = np.arange(4700, 4910, 1)        Cr = np.trapz(ifl(reg), reg)        flentry[mask] = ifl(wv_range[mask]) / Cr        errentry[mask] = ier(wv_range[mask]) / Cr        flgrid.append(flentry)        errgrid.append(errentry)    wv = np.array(wv_range)    flgrid=np.transpose(flgrid)    errgrid=np.transpose(errgrid)    weigrid=errgrid**(-2)    infmask=np.isinf(weigrid)    weigrid[infmask]=0    ################    stack,err=np.zeros([2,len(wv)])    for i in range(len(wv)):        stack[i]=np.sum(flgrid[i]*weigrid[[i]])/np.sum(weigrid[i])        err[i]=1/np.sqrt(np.sum(weigrid[i]))    ################    return wv, stack, errdef Model_fit_stack_normwmean_tot(speclist, tau, metal, A, speczs, wv_range,name, pkl_name, fsps=False):    #############Get redshift info###############    zlist, zbin, zcount, bins = [[], [], [], np.linspace(1, 1.8, 17)]    speczs = np.round(speczs, 2)    for i in range(len(speczs)):        zinput = int(speczs[i] * 100) / 5 / 20.        if zinput < 1:            zinput = 1.0        if zinput >1.8:            zinput = 1.8        zlist.append(zinput)    for i in range(len(bins)):        b = []        for ii in range(len(zlist)):            if bins[i] == zlist[ii]:                b.append(ii)        if len(b) > 0:            zcount.append(len(b))    zbin = sorted(set(zlist))    ##############Stack spectra################    wv,fl,err=Stack_spec_normwmean_tot(speclist,speczs,wv_range)    #############Prep output file###############    chifile='chidat/%s_chidata.fits' % name    prihdr = fits.Header()    prihdu = fits.PrimaryHDU(header=prihdr)    hdulist = fits.HDUList(prihdu)    #############Get list of models to fit againts##############    if fsps==False:        filepath = '../../../bc03_models_for_fit/models/'        modellist = []        for i in range(len(metal)):            m=[]            for ii in range(len(A)):                a = []                for iii in range(len(tau)):                    t = []                    for iv in range(len(zlist)):                        t.append(filepath + 'm%s_a%s_t%s_z%s_model.dat' % (metal[i], A[ii], tau[iii], zlist[iv]))                    a.append(t)                m.append(a)            modellist.append(m)    else:        filepath = '../../../fsps_models_for_fit/models/'        modellist = []        for i in range(len(metal)):            m = []            for ii in range(len(A)):                a = []                for iii in range(len(tau)):                    t = []                    for iv in range(len(zlist)):                        t.append(filepath + 'm%s_a%s_t%s_z%s_model.dat' % (metal[i], A[ii], tau[iii], zlist[iv]))                    a.append(t)                m.append(a)            modellist.append(m)    ###############Pickle spectra##################    pklname='%s.pkl' % pkl_name    if os.path.isfile(pklname)==False:        pklspec = open(pklname, 'wb')        for i in range(len(metal)):            for ii in range(len(A)):                for iii in range(len(tau)):                    mw, mf, me = Stack_model_normwmean_tot(speclist,modellist[i][ii][iii], speczs, zlist, np.arange(wv[0],wv[-1]+5,5))                    cPickle.dump(mf, pklspec, protocol=-1)        pklspec.close()        print 'pickle done'    ##############Create chigrid and add to file#################    outspec = open(pklname, 'rb')    chigrid=np.zeros([len(metal),len(A),len(tau)])    for i in range(len(metal)):        for ii in range(len(A)):            for iii in range(len(tau)):                mf = np.array(cPickle.load(outspec))                chigrid[i][ii][iii]=Identify_stack(fl,err,mf)        inputgrid = np.array(chigrid[i])        spc ='metal_%s' % metal[i]        mchi = fits.ImageHDU(data=inputgrid, name=spc)        hdulist.append(mchi)    outspec.close()    ################Write chigrid file###############    hdulist.writeto(chifile)    returndef Model_fit_stack_normwmean_blue(speclist, tau, metal, A, speczs, wv_range,name, pkl_name, fsps=False):    #############Get redshift info###############    zlist, zbin, zcount, bins = [[], [], [], np.linspace(1, 1.8, 17)]    speczs = np.round(speczs, 2)    for i in range(len(speczs)):        zinput = int(speczs[i] * 100) / 5 / 20.        if zinput < 1:            zinput = 1.0        if zinput >1.8:            zinput = 1.8        zlist.append(zinput)    for i in range(len(bins)):        b = []        for ii in range(len(zlist)):            if bins[i] == zlist[ii]:                b.append(ii)        if len(b) > 0:            zcount.append(len(b))    zbin = sorted(set(zlist))    ##############Stack spectra################    wv,fl,err=Stack_spec_normwmean_blue(speclist,speczs,wv_range)    #############Prep output file###############    chifile='chidat/%s_chidata.fits' % name    prihdr = fits.Header()    prihdu = fits.PrimaryHDU(header=prihdr)    hdulist = fits.HDUList(prihdu)    #############Get list of models to fit againts##############    if fsps==False:        filepath = '../../../bc03_models_for_fit/models/'        modellist = []        for i in range(len(metal)):            m=[]            for ii in range(len(A)):                a = []                for iii in range(len(tau)):                    t = []                    for iv in range(len(zlist)):                        t.append(filepath + 'm%s_a%s_t%s_z%s_model.dat' % (metal[i], A[ii], tau[iii], zlist[iv]))                    a.append(t)                m.append(a)            modellist.append(m)    else:        filepath = '../../../fsps_models_for_fit/models/'        modellist = []        for i in range(len(metal)):            m = []            for ii in range(len(A)):                a = []                for iii in range(len(tau)):                    t = []                    for iv in range(len(zlist)):                        t.append(filepath + 'm%s_a%s_t%s_z%s_model.dat' % (metal[i], A[ii], tau[iii], zlist[iv]))                    a.append(t)                m.append(a)            modellist.append(m)    ###############Pickle spectra##################    pklname='%s.pkl' % pkl_name    if os.path.isfile(pklname)==False:        pklspec = open(pklname, 'wb')        for i in range(len(metal)):            for ii in range(len(A)):                for iii in range(len(tau)):                    mw, mf, me = Stack_model_normwmean_blue(speclist,modellist[i][ii][iii], speczs, zlist, np.arange(wv[0],wv[-1]+5,5))                    cPickle.dump(mf, pklspec, protocol=-1)        pklspec.close()        print 'pickle done'    ##############Create chigrid and add to file#################    outspec = open(pklname, 'rb')    chigrid=np.zeros([len(metal),len(A),len(tau)])    for i in range(len(metal)):        for ii in range(len(A)):            for iii in range(len(tau)):                mf = np.array(cPickle.load(outspec))                chigrid[i][ii][iii]=Identify_stack(fl,err,mf)        inputgrid = np.array(chigrid[i])        spc ='metal_%s' % metal[i]        mchi = fits.ImageHDU(data=inputgrid, name=spc)        hdulist.append(mchi)    outspec.close()    ################Write chigrid file###############    hdulist.writeto(chifile)    returndef Model_fit_stack_normwmean_red(speclist, tau, metal, A, speczs, wv_range,name, pkl_name, fsps=False):    #############Get redshift info###############    zlist, zbin, zcount, bins = [[], [], [], np.linspace(1, 1.8, 17)]    speczs = np.round(speczs, 2)    for i in range(len(speczs)):        zinput = int(speczs[i] * 100) / 5 / 20.        if zinput < 1:            zinput = 1.0        if zinput >1.8:            zinput = 1.8        zlist.append(zinput)    for i in range(len(bins)):        b = []        for ii in range(len(zlist)):            if bins[i] == zlist[ii]:                b.append(ii)        if len(b) > 0:            zcount.append(len(b))    zbin = sorted(set(zlist))    ##############Stack spectra################    wv,fl,err=Stack_spec_normwmean_red(speclist,speczs,wv_range)    #############Prep output file###############    chifile='chidat/%s_chidata.fits' % name    prihdr = fits.Header()    prihdu = fits.PrimaryHDU(header=prihdr)    hdulist = fits.HDUList(prihdu)    #############Get list of models to fit againts##############    if fsps==False:        filepath = '../../../bc03_models_for_fit/models/'        modellist = []        for i in range(len(metal)):            m=[]            for ii in range(len(A)):                a = []                for iii in range(len(tau)):                    t = []                    for iv in range(len(zlist)):                        t.append(filepath + 'm%s_a%s_t%s_z%s_model.dat' % (metal[i], A[ii], tau[iii], zlist[iv]))                    a.append(t)                m.append(a)            modellist.append(m)    else:        filepath = '../../../fsps_models_for_fit/models/'        modellist = []        for i in range(len(metal)):            m = []            for ii in range(len(A)):                a = []                for iii in range(len(tau)):                    t = []                    for iv in range(len(zlist)):                        t.append(filepath + 'm%s_a%s_t%s_z%s_model.dat' % (metal[i], A[ii], tau[iii], zlist[iv]))                    a.append(t)                m.append(a)            modellist.append(m)    ###############Pickle spectra##################    pklname='%s.pkl' % pkl_name    if os.path.isfile(pklname)==False:        pklspec = open(pklname, 'wb')        for i in range(len(metal)):            for ii in range(len(A)):                for iii in range(len(tau)):                    mw, mf, me = Stack_model_normwmean_red(speclist,modellist[i][ii][iii], speczs, zlist, np.arange(wv[0],wv[-1]+5,5))                    cPickle.dump(mf, pklspec, protocol=-1)        pklspec.close()        print 'pickle done'    ##############Create chigrid and add to file#################    outspec = open(pklname, 'rb')    chigrid=np.zeros([len(metal),len(A),len(tau)])    for i in range(len(metal)):        for ii in range(len(A)):            for iii in range(len(tau)):                mf = np.array(cPickle.load(outspec))                chigrid[i][ii][iii]=Identify_stack(fl,err,mf)        inputgrid = np.array(chigrid[i])        spc ='metal_%s' % metal[i]        mchi = fits.ImageHDU(data=inputgrid, name=spc)        hdulist.append(mchi)    outspec.close()    ################Write chigrid file###############    hdulist.writeto(chifile)    return""">10.87 Galaxies"""###get list of spectraids,lmass,rshift=np.array(Readfile('masslist_sep28.dat',1,is_float=False))lmass,rshift=np.array([lmass,rshift]).astype(float)nlist=glob('spec_stacks/*')IDS=[]for i in range(len(ids)):    if 10.87<lmass[i] and 1.0<=rshift[i]<=1.5:        IDS.append(i)speclist=[]for i in range(len(ids[IDS])):    for ii in range(len(nlist)):        if ids[IDS][i]==nlist[ii][12:18]:            speclist.append(nlist[ii])zlist, zbin, zcount, bins = [[], [], [], np.linspace(1, 1.8, 17)]speczs = np.round(rshift[IDS], 2)for i in range(len(speczs)):    zinput=int(speczs[i] * 100) / 5 / 20.    if zinput < 1:        zinput = 1.0    if zinput > 1.8:        zinput = 1.8    zlist.append(zinput)metal=np.array([ 0.0020, 0.0025, 0.0031, 0.0039, 0.0049, 0.0061,  0.0068,  0.0077,  0.0085,  0.0096,  0.0106,                  0.012, 0.0132, 0.014,  0.0150,  0.0164, 0.018,  0.019,  0.021,  0.024, 0.027, 0.03])# metal = np.array([.0001, .0004, .004, .008, .02, ])age=[0.5, 0.57, 0.65, 0.74, 0.84, 0.96, 1.1, 1.25, 1.42,     1.62, 1.85, 2.11, 2.4, 2.74, 3.12, 3.56, 4.05, 4.62, 5.26, 6.0]tau=[0,8.0,8.15,8.28,8.43,8.57,8.72,8.86,9.0,9.14,9.29,9.43,9.57,9.71,9.86,10.0]# for i in range(len(speclist)):#     wv,fl,er=Readfile(speclist[i],1)#     wv/=(1+rshift[IDS][i])#     print wv[0],wv[-1]wvt,flt,ert=Stack_spec_normwmean_tot(speclist,rshift[IDS],np.arange(3500,5500,5))# wvb,flb,erb=Stack_spec_normwmean_blue(speclist,rshift[IDS],np.arange(3250,5500,5))# wvr,flr,err=Stack_spec_normwmean_red(speclist,rshift[IDS],np.arange(3250,5500,5))## CT=np.trapz(flt,wvt)# CB=np.trapz(flb,wvb)# CR=np.trapz(flr,wvr)# flt/=CT# flb/=CB# flr/=CR# ert/=CT# erb/=CB# err/=CR# plt.plot(wvt,flt,'k',label='(4000, 4910)')# plt.plot(wvb,flb,'#6e7da2',label='(4000, 4210)')# plt.plot(wvt,ert,'k')# plt.plot(wvb,erb,'#6e7da2')# plt.axvspan(4000, 4910,color='k', alpha=.2)# plt.axvspan(4000, 4210,color='#6e7da2', alpha=.2)# plt.xlabel('Restframe Wavelength ($\AA$)',size=15)# plt.ylabel('Relative Flux',size=15)# plt.tick_params(axis='both', which='major', labelsize=13)# plt.minorticks_on()# plt.gcf().subplots_adjust(bottom=0.16)# plt.legend(loc=4)# plt.show()## plt.plot(wvt,flt,'k',label='(4000, 4910)')# plt.plot(wvr,flr,'#a13535',label='(4700, 4910)')# plt.plot(wvt,ert,'k')# plt.plot(wvr,err,'#a13535')# plt.axvspan(4000, 4910,color='k', alpha=.2)# plt.axvspan(4700, 4910,color='#a13535', alpha=.2)# plt.xlabel('Restframe Wavelength ($\AA$)',size=15)# plt.ylabel('Relative Flux',size=15)# plt.tick_params(axis='both', which='major', labelsize=13)# plt.minorticks_on()# plt.gcf().subplots_adjust(bottom=0.16)# plt.legend(loc=4)# plt.show()#flist=[]flist2=[]flist3=[]flist4=[]for i in range(len(zlist)):    flist.append('../../../fsps_models_for_fit/models/m0.0096_a1.85_t0_z%s_model.dat' % zlist[i])    flist2.append('../../../fsps_models_for_fit/models/m0.019_a1.25_t0_z%s_model.dat' % zlist[i])    flist3.append('../../../fsps_models_for_fit/models/m0.015_a1.62_t0_z%s_model.dat' % zlist[i])    flist4.append('../../../fsps_models_for_fit/models/m0.0132_a1.62_t0_z%s_model.dat' % zlist[i])#ftwv,fts,fte=Stack_model_normwmean_tot(speclist,flist, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))ftwv2,fts2,fte2=Stack_model_normwmean_tot(speclist,flist2, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))ftwv3,fts3,fte3=Stack_model_normwmean_tot(speclist,flist3, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))ftwv4,fts4,fte4=Stack_model_normwmean_tot(speclist,flist4, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))# fbwv,fbs,fbe=Stack_model_normwmean_blue(speclist,flist, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))# fbwv2,fbs2,fbe2=Stack_model_normwmean_blue(speclist,flist2, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))# frwv,frs,fre=Stack_model_normwmean_red(speclist,flist, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))# frwv2,frs2,fre2=Stack_model_normwmean_red(speclist,flist2, speczs, zlist, np.arange(wvt[0],wvt[-1]+5,5))## CT=np.trapz(fts,ftwv)# CB=np.trapz(fbs,fbwv)# CR=np.trapz(frs,frwv)# fts/=CT# fbs/=CB# frs/=CR# fte/=CT# fbe/=CB# fre/=CR"""total"""# S1=Scale_model(flt,ert,fts)# S2=Scale_model(flt,ert,fts2)#chi=np.zeros(4)chi[0]=np.round(sum(((flt - fts) / ert) ** 2),2)chi[1]=np.round(sum(((flt - fts2) / ert) ** 2),2)chi[2]=np.round(sum(((flt - fts3) / ert) ** 2),2)chi[3]=np.round(sum(((flt - fts4) / ert) ** 2),2)plt.plot(wvt,flt,'#6e7da2',label='(4000, 4910)')plt.plot(ftwv,fts, label='$\chi^2$=%s' % chi[0])plt.plot(ftwv,fts2, label='$\chi^2$=%s' % chi[1])plt.plot(ftwv,fts3, label='$\chi^2$=%s' % chi[2])plt.plot(ftwv,fts4, label='$\chi^2$=%s' % chi[3])plt.axvspan(4000, 4910,color='k', alpha=.2)plt.xlabel('Restframe Wavelength ($\AA$)',size=15)plt.ylabel('Relative Flux',size=15)plt.tick_params(axis='both', which='major', labelsize=13)plt.minorticks_on()plt.gcf().subplots_adjust(bottom=0.16)plt.legend(loc=4)plt.show()# plt.savefig('../research_plots/norm_total_bfs.png')# plt.close()"""blue"""# S1=Scale_model(flb,erb,fbs)# S2=Scale_model(flb,erb,fbs2)## S1,S2=[1,1]## chi=np.zeros(2)# chi[0]=np.round(sum(((flb - fbs*S1) / erb) ** 2),2)# chi[1]=np.round(sum(((flb - fbs2*S2) / erb) ** 2),2)## plt.plot(wvb,flb,'#6e7da2',label='(4000, 4210)')# plt.plot(fbwv,fbs*S1, label='$\chi^2$=%s' % chi[0])# plt.plot(fbwv2,fbs2*S2, label='$\chi^2$=%s' % chi[1])# plt.axvspan(4000, 4210,color='k', alpha=.2)# plt.xlabel('Restframe Wavelength ($\AA$)',size=15)# plt.ylabel('Relative Flux',size=15)# plt.tick_params(axis='both', which='major', labelsize=13)# plt.minorticks_on()# plt.gcf().subplots_adjust(bottom=0.16)# plt.legend(loc=4)# plt.show()# plt.savefig('../research_plots/norm_blue.png')# plt.close()"""red"""## S1=Scale_model(flr,err,frs)# S2=Scale_model(flr,err,frs2)## chi=np.zeros(2)# chi[0]=np.round(sum(((flr - frs*S1) / err) ** 2),2)# chi[1]=np.round(sum(((flr - frs2*S2) / err) ** 2),2)## plt.plot(wvr,flr,'#6e7da2',label='(4700, 4910)')# plt.plot(frwv,frs*S1, label='$\chi^2$=%s' % chi[0])# plt.plot(frwv2,frs2*S2, label='$\chi^2$=%s' % chi[1])# plt.axvspan(4700, 4910,color='k', alpha=.2)# plt.xlabel('Restframe Wavelength ($\AA$)',size=15)# plt.ylabel('Relative Flux',size=15)# plt.tick_params(axis='both', which='major', labelsize=13)# plt.minorticks_on()# plt.gcf().subplots_adjust(bottom=0.16)# plt.legend(loc=4)# # plt.show()# plt.savefig('../research_plots/norm_red.png')# plt.close()"""fitting"""# M,A=np.meshgrid(metal,age)## Model_fit_stack_normwmean_tot(speclist,tau,metal,age,rshift[IDS],np.arange(3250,5500,5),#                               'nwin_tot_stackfit15','nwin_tot_spec15',fsps=True)## Model_fit_stack_normwmean_blue(speclist,tau,metal,age,rshift[IDS],np.arange(3250,5500,5),#                               'nwin_blue_stackfit15','nwin_blue_spec15',fsps=True)## Model_fit_stack_normwmean_red(speclist,tau,metal,age,rshift[IDS],np.arange(3250,5500,5),#                               'nwin_red_stackfit15','nwin_red_spec15',fsps=True)## Pr,bfage,bfmetal=Analyze_Stack_avgage('chidat/nwin_tot_stackfit3_chidata.fits', np.array(tau),metal,age)# onesig,twosig=Likelihood_contours(age,metal,Pr)# levels=np.array([twosig,onesig])# # levels=np.array([201.66782781,  908.392327])# print levels# plt.contour(M,A,Pr,levels,colors='k',linewidths=2)# plt.contourf(M,A,Pr,40,cmap=colmap)# plt.plot(bfmetal,bfage,'cp',label='\nBest fit\nt=%s Gyrs\nZ=%s Z$_\odot$' % (bfage,np.round(bfmetal/0.019,2)))# # plt.xticks([0,.005,.01,.015,.02,.025,.03],np.round(np.array([0,.005,.01,.015,.02,.025,.03])/0.02,2))# plt.tick_params(axis='both', which='major', labelsize=17)# plt.gcf().subplots_adjust(bottom=0.16)# plt.minorticks_on()# plt.xlabel('Metallicity (Z$_\odot$)')# plt.ylabel('Age (Gyrs)')# plt.legend()# plt.show()# plt.savefig('../research_plots/norm_total_likelihood15.png')# plt.close()## Pr,bfage,bfmetal=Analyze_Stack_avgage('chidat/nwin_blue_stackfit15_chidata.fits', np.array(tau),metal,age)# onesig,twosig=Likelihood_contours(age,metal,Pr)# levels=np.array([twosig,onesig])# # levels=np.array([201.66782781,  908.392327])# print levels# plt.contour(M,A,Pr,levels,colors='k',linewidths=2)# plt.contourf(M,A,Pr,40,cmap=colmap)# plt.plot(bfmetal,bfage,'cp',label='\nBest fit\nt=%s Gyrs\nZ=%s Z$_\odot$' % (bfage,np.round(bfmetal/0.019,2)))# plt.xticks([0,.005,.01,.015,.02,.025,.03],np.round(np.array([0,.005,.01,.015,.02,.025,.03])/0.02,2))# plt.tick_params(axis='both', which='major', labelsize=17)# plt.gcf().subplots_adjust(bottom=0.16)# plt.minorticks_on()# plt.xlabel('Metallicity (Z$_\odot$)')# plt.ylabel('Age (Gyrs)')# plt.legend()# # plt.show()# plt.savefig('../research_plots/norm_blue_likelihood15.png')# plt.close()## Pr,bfage,bfmetal=Analyze_Stack_avgage('chidat/nwin_red_stackfit15_chidata.fits', np.array(tau),metal,age)# onesig,twosig=Likelihood_contours(age,metal,Pr)# levels=np.array([twosig,onesig])# # levels=np.array([201.66782781,  908.392327])# print levels# plt.contour(M,A,Pr,levels,colors='k',linewidths=2)# plt.contourf(M,A,Pr,40,cmap=colmap)# plt.plot(bfmetal,bfage,'cp',label='\nBest fit\nt=%s Gyrs\nZ=%s Z$_\odot$' % (bfage,np.round(bfmetal/0.019,2)))# plt.xticks([0,.005,.01,.015,.02,.025,.03],np.round(np.array([0,.005,.01,.015,.02,.025,.03])/0.02,2))# plt.tick_params(axis='both', which='major', labelsize=17)# plt.gcf().subplots_adjust(bottom=0.16)# plt.minorticks_on()# plt.xlabel('Metallicity (Z$_\odot$)')# plt.ylabel('Age (Gyrs)')# plt.legend()# # plt.show()# plt.savefig('../research_plots/norm_red_likelihood15.png')# plt.close()